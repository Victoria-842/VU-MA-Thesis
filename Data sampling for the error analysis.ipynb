{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "90297ad1-fc9c-4dd0-af29-1685862d4371",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78e0ae71-d9a5-47d5-b439-415d7d0ae0dd",
   "metadata": {},
   "source": [
    "# Data sampling for the error analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df0b63ac-352e-4dd6-a93a-78452bdc5ff3",
   "metadata": {},
   "source": [
    "## Statistics for error analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "271ded2b-441a-4390-8b3b-37fdbdf63712",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                   post          class  \\\n",
      "0     bernie sanders : white people dont know what i...       not_hate   \n",
      "1       \" what do we do if ? \" \" - antifa attacks wi...       not_hate   \n",
      "2                      the realist report - 9/11 debate       not_hate   \n",
      "3     . #alert ; #splc has posted hitlists online th...       not_hate   \n",
      "4     if other groups want to wine about optics and ...       not_hate   \n",
      "...                                                 ...            ...   \n",
      "4121  first isis is the jv team then they were conta...       not_hate   \n",
      "4122  that is false. 2nd generation immigrants from ...  implicit_hate   \n",
      "4123  racial identity  and its hostilities  are on t...       not_hate   \n",
      "4124  as do the younger . what generation makes up a...       not_hate   \n",
      "4125  pakistani sex-gang attacks covered up for fear...  implicit_hate   \n",
      "\n",
      "         prediction implicit_class  \n",
      "0     implicit_hate            NaN  \n",
      "1          not_hate            NaN  \n",
      "2          not_hate            NaN  \n",
      "3     implicit_hate            NaN  \n",
      "4          not_hate            NaN  \n",
      "...             ...            ...  \n",
      "4121  implicit_hate            NaN  \n",
      "4122  implicit_hate    inferiority  \n",
      "4123       not_hate            NaN  \n",
      "4124  implicit_hate            NaN  \n",
      "4125  implicit_hate  stereotypical  \n",
      "\n",
      "[4126 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('results_24shot_4126_PROMPT2_2_implicit_labels.csv')  \n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "903c1ed2-3b80-49e3-98ef-63386dc365b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== IMPLICIT HATE PREDICTION STATISTICS BY IMPLICIT CLASS ===\n",
      "\n",
      "Total implicit hate instances: 1250\n",
      "Implicit class categories: ['incitement', 'inferiority', 'irony', 'other', 'stereotypical', 'threatening', 'white_grievance']\n",
      "\n",
      "INCITEMENT (n=248)\n",
      "Predicted as implicit_hate: 42.7%\n",
      "Predicted as explicit_hate: 35.9%\n",
      "Predicted as not_hate: 21.4%\n",
      "\n",
      "INFERIORITY (n=169)\n",
      "Predicted as implicit_hate: 38.5%\n",
      "Predicted as explicit_hate: 24.9%\n",
      "Predicted as not_hate: 36.7%\n",
      "\n",
      "IRONY (n=156)\n",
      "Predicted as implicit_hate: 42.9%\n",
      "Predicted as explicit_hate: 21.2%\n",
      "Predicted as not_hate: 35.9%\n",
      "\n",
      "OTHER (n=16)\n",
      "Predicted as implicit_hate: 62.5%\n",
      "Predicted as explicit_hate: 18.8%\n",
      "Predicted as not_hate: 18.8%\n",
      "\n",
      "STEREOTYPICAL (n=221)\n",
      "Predicted as implicit_hate: 48.4%\n",
      "Predicted as explicit_hate: 35.3%\n",
      "Predicted as not_hate: 16.3%\n",
      "\n",
      "THREATENING (n=130)\n",
      "Predicted as implicit_hate: 9.2%\n",
      "Predicted as explicit_hate: 56.9%\n",
      "Predicted as not_hate: 33.8%\n",
      "\n",
      "WHITE_GRIEVANCE (n=301)\n",
      "Predicted as implicit_hate: 56.5%\n",
      "Predicted as explicit_hate: 29.9%\n",
      "Predicted as not_hate: 13.6%\n",
      "\n",
      "=== SUMMARY TABLE ===\n",
      "Implicit Class  Total    Implicit%  Explicit%  Not Hate% \n",
      "------------------------------------------------------------\n",
      "incitement      248      42.7       35.9       21.4      \n",
      "inferiority     169      38.5       24.9       36.7      \n",
      "irony           156      42.9       21.2       35.9      \n",
      "other           16       62.5       18.8       18.8      \n",
      "stereotypical   221      48.4       35.3       16.3      \n",
      "threatening     130      9.2        56.9       33.8      \n",
      "white_grievance 301      56.5       29.9       13.6      \n",
      "\n",
      "=== OVERALL PERFORMANCE ===\n",
      "Overall implicit hate detection rate: 43.0%\n",
      "Overall misclassified as explicit: 33.0%\n",
      "Overall misclassified as not hate: 24.0%\n",
      "\n",
      "Best detected implicit class: other (62.5%)\n",
      "Worst detected implicit class: threatening (9.2%)\n"
     ]
    }
   ],
   "source": [
    "implicit_hate_df = df[df['class'] == 'implicit_hate'].copy()\n",
    "\n",
    "print(\"=== IMPLICIT HATE PREDICTION STATISTICS BY IMPLICIT CLASS ===\\n\")\n",
    "\n",
    "#unique implicit class labels\n",
    "implicit_classes = implicit_hate_df['implicit_class'].unique()\n",
    "implicit_classes = sorted([cls for cls in implicit_classes if pd.notna(cls)])\n",
    "\n",
    "print(f\"Total implicit hate instances: {len(implicit_hate_df)}\")\n",
    "print(f\"Implicit class categories: {implicit_classes}\\n\")\n",
    "\n",
    "#statistics for each implicit class\n",
    "results = []\n",
    "\n",
    "for implicit_class in implicit_classes:\n",
    "    # Filter for current implicit class\n",
    "    class_df = implicit_hate_df[implicit_hate_df['implicit_class'] == implicit_class]\n",
    "    total_count = len(class_df)\n",
    "    \n",
    "    if total_count == 0:\n",
    "        continue\n",
    "    \n",
    "    #predictions for each category\n",
    "    pred_counts = class_df['prediction'].value_counts()\n",
    "    implicit_pct = (pred_counts.get('implicit_hate', 0) / total_count) * 100\n",
    "    explicit_pct = (pred_counts.get('explicit_hate', 0) / total_count) * 100\n",
    "    not_hate_pct = (pred_counts.get('not_hate', 0) / total_count) * 100\n",
    "    \n",
    "    results.append({\n",
    "        'implicit_class': implicit_class,\n",
    "        'total_count': total_count,\n",
    "        'implicit_hate_pct': implicit_pct,\n",
    "        'explicit_hate_pct': explicit_pct,\n",
    "        'not_hate_pct': not_hate_pct\n",
    "    })\n",
    "    \n",
    "    print(f\"{implicit_class.upper()} (n={total_count})\")\n",
    "    print(f\"Predicted as implicit_hate: {implicit_pct:.1f}%\")\n",
    "    print(f\"Predicted as explicit_hate: {explicit_pct:.1f}%\")\n",
    "    print(f\"Predicted as not_hate: {not_hate_pct:.1f}%\")\n",
    "    print()\n",
    "\n",
    "print(\"=== SUMMARY TABLE ===\")\n",
    "print(f\"{'Implicit Class':<15} {'Total':<8} {'Implicit%':<10} {'Explicit%':<10} {'Not Hate%':<10}\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "for result in results:\n",
    "    print(f\"{result['implicit_class']:<15} {result['total_count']:<8} \"\n",
    "          f\"{result['implicit_hate_pct']:<10.1f} {result['explicit_hate_pct']:<10.1f} \"\n",
    "          f\"{result['not_hate_pct']:<10.1f}\")\n",
    "\n",
    "#general statistics\n",
    "print(f\"\\n=== OVERALL PERFORMANCE ===\")\n",
    "total_implicit = len(implicit_hate_df)\n",
    "overall_correct = len(implicit_hate_df[implicit_hate_df['prediction'] == 'implicit_hate'])\n",
    "overall_as_explicit = len(implicit_hate_df[implicit_hate_df['prediction'] == 'explicit_hate'])\n",
    "overall_as_not_hate = len(implicit_hate_df[implicit_hate_df['prediction'] == 'not_hate'])\n",
    "\n",
    "print(f\"Overall implicit hate detection rate: {(overall_correct/total_implicit)*100:.1f}%\")\n",
    "print(f\"Overall misclassified as explicit: {(overall_as_explicit/total_implicit)*100:.1f}%\")\n",
    "print(f\"Overall misclassified as not hate: {(overall_as_not_hate/total_implicit)*100:.1f}%\")\n",
    "\n",
    "#best and worst performing categories\n",
    "if results:\n",
    "    best_detection = max(results, key=lambda x: x['implicit_hate_pct'])\n",
    "    worst_detection = min(results, key=lambda x: x['implicit_hate_pct'])\n",
    "    \n",
    "    print(f\"\\nBest detected implicit class: {best_detection['implicit_class']} ({best_detection['implicit_hate_pct']:.1f}%)\")\n",
    "    print(f\"Worst detected implicit class: {worst_detection['implicit_class']} ({worst_detection['implicit_hate_pct']:.1f}%)\")\n",
    "\n",
    "### The code was created with the help of Claude.ai\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "287ab382-6029-47be-b631-45fcaf93a0fd",
   "metadata": {},
   "source": [
    "## Random data sampling for error analysis (100 sentences per class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "97e8e55f-1ddc-4a5c-8ae3-5dcb02041d5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Warning: No data available for implicit_class 'nan', skipping...\n",
      "    Warning: Only 12 samples available, taking all available samples\n",
      "    Warning: Only 33 samples available, taking all available samples\n",
      "    Warning: Only 3 samples available, taking all available samples\n",
      "    Warning: Only 10 samples available, taking all available samples\n",
      "    Warning: Only 3 samples available, taking all available samples\n",
      "\n",
      "Sampling completed successfully!\n",
      "Check the output file: 100_randomly_sampled_data.csv\n"
     ]
    }
   ],
   "source": [
    "def sample_csv_data(input_file, output_file, samples_per_class=100, max_samples=16):\n",
    "    \"\"\"\n",
    "    Sample CSV data with equal distribution across all 3 prediction labels for each implicit_class.\n",
    "    \n",
    "    Args:\n",
    "        input_file (str): Path to input CSV file\n",
    "        output_file (str): Path to output CSV file\n",
    "        samples_per_class (int): Number of samples per implicit_class (default: 100)\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(input_file)\n",
    "    implicit_classes = df['implicit_class'].unique()\n",
    "    all_predictions = ['explicit_hate', 'implicit_hate', 'not_hate']  # All 3 expected prediction labels\n",
    "    \n",
    "    sampled_data = []\n",
    "    sampling_report = defaultdict(lambda: defaultdict(int))\n",
    "    \n",
    "    for implicit_class in implicit_classes:\n",
    "        \n",
    "        class_data = df[df['implicit_class'] == implicit_class].copy()\n",
    "        \n",
    "        if len(class_data) == 0:\n",
    "            print(f\"  Warning: No data available for implicit_class '{implicit_class}', skipping...\")\n",
    "            continue\n",
    "\n",
    "        if implicit_class == 'other':\n",
    "            target_samples = min(len(class_data), 16) # Max 16 for 'other' class\n",
    "            if len(class_data) != max_samples:\n",
    "                print(f\"Warning: Expected {max_samples} samples but found {len(class_data)} samples\")\n",
    "        if len(class_data) < max_samples:\n",
    "            print(f\"Error: Not enough data! Need {max_samples} samples but only {len(class_data)} available\")\n",
    "            return None\n",
    "        else:\n",
    "            target_samples = samples_per_class  # 100 for other classes\n",
    "        \n",
    "        samples_per_prediction = target_samples // 3  # divide by 3 (all prediction labels)\n",
    "        remainder = target_samples % 3\n",
    "\n",
    "        if remainder > 0:\n",
    "        \n",
    "            class_samples = []\n",
    "        \n",
    "        for i, prediction in enumerate(all_predictions):\n",
    "            n_samples = samples_per_prediction\n",
    "            if i < remainder: \n",
    "                n_samples += 1\n",
    "            \n",
    "            pred_data = class_data[class_data['prediction'] == prediction]\n",
    "            available_samples = len(pred_data)\n",
    "                        \n",
    "            if available_samples == 0:\n",
    "                print(f\"    Warning: No samples available for prediction '{prediction}'\")\n",
    "                continue\n",
    "            \n",
    "            if available_samples >= n_samples:\n",
    "                sampled = pred_data.sample(n=n_samples, random_state=42)\n",
    "            else:\n",
    "                print(f\"    Warning: Only {available_samples} samples available, taking all available samples\")\n",
    "                sampled = pred_data.copy()  # Take all available samples\n",
    "            \n",
    "            class_samples.append(sampled)\n",
    "            sampling_report[implicit_class][prediction] = len(sampled)\n",
    "        \n",
    "        if class_samples:\n",
    "            class_combined = pd.concat(class_samples, ignore_index=True)\n",
    "            sampled_data.append(class_combined)\n",
    "    \n",
    "    if sampled_data:\n",
    "        final_df = pd.concat(sampled_data, ignore_index=True)\n",
    "        \n",
    "        final_df = final_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "        final_df.to_csv(output_file, index=False)\n",
    "        \n",
    "        return final_df\n",
    "    \n",
    "    else:\n",
    "        print(\"No data was sampled. Please check your input file and criteria.\")\n",
    "        return None\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    input_csv = \"results_24shot_4126_PROMPT2_2_implicit_labels.csv\"  # Replace with your input file path\n",
    "    output_csv = \"100_randomly_sampled_data.csv\"  # Replace with desired output file path\n",
    "    \n",
    "    try:\n",
    "        result = sample_csv_data(input_csv, output_csv, samples_per_class=100)\n",
    "        \n",
    "        if result is not None:\n",
    "            print(f\"\\nSampling completed successfully!\")\n",
    "            print(f\"Check the output file: {output_csv}\")\n",
    "        \n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: Input file '{input_csv}' not found.\")\n",
    "        print(\"Please update the 'input_csv' variable with the correct file path.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "\n",
    "### The code was created with the help of Claude.ai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a8170e5e-1952-4797-8415-b1d71f8a27de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "implicit_class\n",
       "incitement         100\n",
       "stereotypical      100\n",
       "white_grievance    100\n",
       "inferiority        100\n",
       "irony               99\n",
       "threatening         79\n",
       "other               16\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('100_randomly_sampled_data.csv')\n",
    "df['implicit_class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d1ac0818-69a5-4899-b5ba-803fe3422e17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction       explicit_hate  implicit_hate  not_hate\n",
      "implicit_class                                         \n",
      "incitement                  34             33        33\n",
      "inferiority                 34             33        33\n",
      "irony                       33             33        33\n",
      "other                        3             10         3\n",
      "stereotypical               34             33        33\n",
      "threatening                 34             12        33\n",
      "white_grievance             34             33        33\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('100_randomly_sampled_data.csv')\n",
    "counts = df.groupby('implicit_class')['prediction'].value_counts().unstack(fill_value=0)\n",
    "print(counts)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
